{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbd0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./venv/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in ./venv/lib/python3.11/site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c08656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c3a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de y_df (204,)\n",
      "Shape de X_df (204, 777)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor__variance_larger_than_standard_deviation</th>\n",
       "      <th>valor__has_duplicate_max</th>\n",
       "      <th>valor__has_duplicate_min</th>\n",
       "      <th>valor__has_duplicate</th>\n",
       "      <th>valor__sum_values</th>\n",
       "      <th>valor__abs_energy</th>\n",
       "      <th>valor__mean_abs_change</th>\n",
       "      <th>valor__mean_change</th>\n",
       "      <th>valor__mean_second_derivative_central</th>\n",
       "      <th>valor__median</th>\n",
       "      <th>...</th>\n",
       "      <th>valor__fourier_entropy__bins_5</th>\n",
       "      <th>valor__fourier_entropy__bins_10</th>\n",
       "      <th>valor__fourier_entropy__bins_100</th>\n",
       "      <th>valor__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>valor__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>valor__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>valor__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>valor__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>valor__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>valor__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.734864</td>\n",
       "      <td>33.127876</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>-7.016291e-07</td>\n",
       "      <td>2.248299e-07</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314393</td>\n",
       "      <td>0.418924</td>\n",
       "      <td>0.652842</td>\n",
       "      <td>1.222197</td>\n",
       "      <td>1.779523</td>\n",
       "      <td>2.375477</td>\n",
       "      <td>3.002084</td>\n",
       "      <td>3.596227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300720</td>\n",
       "      <td>34.903172</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>-5.418686e-07</td>\n",
       "      <td>-1.194152e-07</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273489</td>\n",
       "      <td>0.370036</td>\n",
       "      <td>0.793862</td>\n",
       "      <td>1.148054</td>\n",
       "      <td>1.645622</td>\n",
       "      <td>2.196140</td>\n",
       "      <td>2.777400</td>\n",
       "      <td>3.365738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.477569</td>\n",
       "      <td>16.164088</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>-4.119189e-06</td>\n",
       "      <td>-1.837347e-06</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235155</td>\n",
       "      <td>0.305728</td>\n",
       "      <td>0.574520</td>\n",
       "      <td>1.649418</td>\n",
       "      <td>2.545695</td>\n",
       "      <td>3.470808</td>\n",
       "      <td>4.431796</td>\n",
       "      <td>5.335461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>6.087861</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>-1.726074e-06</td>\n",
       "      <td>-1.227095e-07</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239211</td>\n",
       "      <td>0.339942</td>\n",
       "      <td>0.553027</td>\n",
       "      <td>1.663552</td>\n",
       "      <td>2.610122</td>\n",
       "      <td>3.569896</td>\n",
       "      <td>4.564650</td>\n",
       "      <td>5.506580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.562194</td>\n",
       "      <td>28.034003</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>1.992890e-07</td>\n",
       "      <td>-9.882629e-09</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367289</td>\n",
       "      <td>0.493589</td>\n",
       "      <td>0.808665</td>\n",
       "      <td>1.479723</td>\n",
       "      <td>2.184056</td>\n",
       "      <td>2.926665</td>\n",
       "      <td>3.690862</td>\n",
       "      <td>4.417537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor__variance_larger_than_standard_deviation  valor__has_duplicate_max  \\\n",
       "0                                             0.0                       0.0   \n",
       "1                                             0.0                       0.0   \n",
       "2                                             0.0                       0.0   \n",
       "3                                             0.0                       0.0   \n",
       "4                                             0.0                       0.0   \n",
       "\n",
       "   valor__has_duplicate_min  valor__has_duplicate  valor__sum_values  \\\n",
       "0                       0.0                   1.0          -0.734864   \n",
       "1                       0.0                   1.0           0.300720   \n",
       "2                       0.0                   1.0          -0.477569   \n",
       "3                       0.0                   1.0           0.007569   \n",
       "4                       0.0                   1.0          -0.562194   \n",
       "\n",
       "   valor__abs_energy  valor__mean_abs_change  valor__mean_change  \\\n",
       "0          33.127876                0.003897       -7.016291e-07   \n",
       "1          34.903172                0.004165       -5.418686e-07   \n",
       "2          16.164088                0.002264       -4.119189e-06   \n",
       "3           6.087861                0.001689       -1.726074e-06   \n",
       "4          28.034003                0.004050        1.992890e-07   \n",
       "\n",
       "   valor__mean_second_derivative_central  valor__median  ...  \\\n",
       "0                           2.248299e-07      -0.000244  ...   \n",
       "1                          -1.194152e-07      -0.001068  ...   \n",
       "2                          -1.837347e-06      -0.000092  ...   \n",
       "3                          -1.227095e-07       0.000244  ...   \n",
       "4                          -9.882629e-09       0.000809  ...   \n",
       "\n",
       "   valor__fourier_entropy__bins_5  valor__fourier_entropy__bins_10  \\\n",
       "0                        0.314393                         0.418924   \n",
       "1                        0.273489                         0.370036   \n",
       "2                        0.235155                         0.305728   \n",
       "3                        0.239211                         0.339942   \n",
       "4                        0.367289                         0.493589   \n",
       "\n",
       "   valor__fourier_entropy__bins_100  \\\n",
       "0                          0.652842   \n",
       "1                          0.793862   \n",
       "2                          0.574520   \n",
       "3                          0.553027   \n",
       "4                          0.808665   \n",
       "\n",
       "   valor__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                        1.222197   \n",
       "1                                        1.148054   \n",
       "2                                        1.649418   \n",
       "3                                        1.663552   \n",
       "4                                        1.479723   \n",
       "\n",
       "   valor__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                        1.779523   \n",
       "1                                        1.645622   \n",
       "2                                        2.545695   \n",
       "3                                        2.610122   \n",
       "4                                        2.184056   \n",
       "\n",
       "   valor__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                        2.375477   \n",
       "1                                        2.196140   \n",
       "2                                        3.470808   \n",
       "3                                        3.569896   \n",
       "4                                        2.926665   \n",
       "\n",
       "   valor__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                        3.002084   \n",
       "1                                        2.777400   \n",
       "2                                        4.431796   \n",
       "3                                        4.564650   \n",
       "4                                        3.690862   \n",
       "\n",
       "   valor__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                        3.596227   \n",
       "1                                        3.365738   \n",
       "2                                        5.335461   \n",
       "3                                        5.506580   \n",
       "4                                        4.417537   \n",
       "\n",
       "   valor__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                0.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   valor__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                        0.232910  \n",
       "1                                        0.266963  \n",
       "2                                        0.207986  \n",
       "3                                        0.154306  \n",
       "4                                        0.336108  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File(\"train.h5\", \"r\") as f_pd:\n",
    "    y_data = f_pd['y'][:]  \n",
    "y_df = pd.Series(y_data)  \n",
    "\n",
    "\n",
    "x_df = pd.read_pickle(\"all_features.pkl\")\n",
    "x_df.head()\n",
    "print(\"Shape de y_df\", y_df.shape)\n",
    "print(\"Shape de X_df\", x_df.shape)\n",
    "\n",
    "value_counts = y_df.value_counts()\n",
    "x_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc504a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556d44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, kernel_type='linear', regularization_parameter=10000.0, max_iterations=500, polynomial_degree=3, gauss_gamma=1,sigmoid_alpha=0.001, sigmoid_c=0):\n",
    "\n",
    "        self.kernel_type = kernel_type\n",
    "        self.polynomial_degree = polynomial_degree\n",
    "        self.gauss_gamma = gauss_gamma\n",
    "        self.regularization_parameter = regularization_parameter\n",
    "        self.max_iterations = max_iterations\n",
    "        self.support_vector_indices = None\n",
    "        #Kernell sgimoideo\n",
    "        self.sigmoid_alpha = sigmoid_alpha\n",
    "        self.sigmoid_c = sigmoid_c\n",
    "\n",
    "    def _compute_kernel_matrix(self, X1, X2):\n",
    "\n",
    "        # selecciÃ³n del kernel\n",
    "        if self.kernel_type == 'linear':\n",
    "            return np.dot(X1, X2.T)\n",
    "        elif self.kernel_type == 'poly':\n",
    "            return np.dot(X1, X2.T)**self.polynomial_degree\n",
    "        elif self.kernel_type == 'gauss':\n",
    "            if X1 is X2:\n",
    "                pairwise_distances = np.sum((X1[:, np.newaxis] - X2)**2, axis=2)\n",
    "            else:\n",
    "                pairwise_distances = np.sum((X2 - X1[:, np.newaxis])**2, axis=2)\n",
    "            return np.exp(-self.gauss_gamma * pairwise_distances)\n",
    "        elif self.kernel_type == 'sigmoid':  # Caso para el kernel sigmoideo\n",
    "          return np.tanh(self.sigmoid_alpha * np.dot(X1, X2.T) + self.sigmoid_c)\n",
    "        else:\n",
    "            raise ValueError(f\"Kernel no soportado: {self.kernel_type}\")\n",
    "\n",
    "    def fit(self, feature_matrix, target_labels):\n",
    "        self.features = feature_matrix.copy()\n",
    "        self.labels = target_labels * 2 - 1  #etiquetas [0, 1] a [-1, 1]\n",
    "        self.lagrange_multipliers = np.zeros_like(self.labels, dtype=float) # Estos son nÃºmeros que va a aprender para decidir quÃ© puntos son vectores de soporte.\n",
    "\n",
    "        kernel_values = self._compute_kernel_matrix(self.features, self.features) # k(x(i), x(j))\n",
    "\n",
    "\n",
    "        # el \"self.labels\" y \"self.labels[:, np.newaxis]\" representa las clases reales de los datos de entrenamiento\n",
    "        self.kernel_matrix = kernel_values * self.labels[:, np.newaxis] * self.labels #t(i)*t(j)*k(x(i)T, x(j))\n",
    "\n",
    "        # optimizaciÃ³n // para encontrar los multiplicadores de Lagrange\n",
    "        for _ in range(self.max_iterations):\n",
    "            for primary_index in range(len(self.lagrange_multipliers)):\n",
    "                secondary_index = np.random.randint(0, len(self.lagrange_multipliers))\n",
    "\n",
    "                quadratic_term = self.kernel_matrix[[[primary_index, primary_index], [secondary_index, secondary_index]],\n",
    "                                                     [[primary_index, secondary_index], [primary_index, secondary_index]]]\n",
    "\n",
    "                current_multipliers = self.lagrange_multipliers[[primary_index, secondary_index]]\n",
    "\n",
    "                error_terms = 1 - np.sum(self.lagrange_multipliers * self.kernel_matrix[[primary_index, secondary_index]], axis=1)\n",
    "\n",
    "                direction_vector = np.array([-self.labels[secondary_index], self.labels[primary_index]])\n",
    "\n",
    "                optimal_step = np.dot(error_terms, direction_vector) / (np.dot(np.dot(quadratic_term, direction_vector), direction_vector) + 1E-15)\n",
    "\n",
    "                constrained_step = self._restrict_to_valid_range(optimal_step, current_multipliers, direction_vector)\n",
    "\n",
    "                self.lagrange_multipliers[[primary_index, secondary_index]] = current_multipliers + direction_vector * constrained_step #multiplicadores de lagrange optimizados\n",
    "\n",
    "        # identificamos los vectores de soporte y calcular el sesgo\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(self.lagrange_multipliers > 1E-15)[0] # Identifica quÃ© puntos de entrenamiento son vectores de soporte.\n",
    "\n",
    "        if len(self.support_vector_indices) > 0: # calculo de sedsgo\n",
    "            self.b = np.sum((1.0 - np.sum(self.kernel_matrix[self.support_vector_indices] *\n",
    "                                            self.lagrange_multipliers, axis=1)) *\n",
    "                               self.labels[self.support_vector_indices]) / len(self.support_vector_indices)\n",
    "        else:\n",
    "            self.b = 0.0\n",
    "\n",
    "        if self.kernel_type == 'linear': # CÃ¡lculo del vector de pesos W (para kernel lineales)\n",
    "            self.W = np.sum((self.lagrange_multipliers * self.labels)[:, np.newaxis] * self.features, axis=0)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        #valores aplicando el kernel\n",
    "        kernel_values = self._compute_kernel_matrix(X, self.features)\n",
    "\n",
    "        #predicciones [1, -1]\n",
    "        decision_values = np.sum(kernel_values * self.labels * self.lagrange_multipliers, axis=1) + self.b\n",
    "        return (np.sign(decision_values) + 1) // 2  # conversion a [0,1]\n",
    "\n",
    "    def _restrict_to_valid_range(self, step_size, current_values, direction_vector):\n",
    "        #restringimos el paso de optimizaciÃ³n para mantener los multiplicadores dentro de los lÃ­mites permitidos\n",
    "\n",
    "        step_size = (np.clip(current_values + step_size*direction_vector, 0, self.regularization_parameter) -\n",
    "                    current_values)[1]/direction_vector[1]\n",
    "        return (np.clip(current_values + step_size*direction_vector, 0, self.regularization_parameter) -\n",
    "               current_values)[0]/direction_vector[0]\n",
    "\n",
    "    def get_support_vectors(self):\n",
    "\n",
    "        if self.support_vector_indices is None:\n",
    "            raise ValueError(\"El modelo debe ser entrenado antes de obtener los vectores de soporte\")\n",
    "\n",
    "        return self.support_vector_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b181d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x_df.to_numpy())\n",
    "y = y_df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdd48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauss Kernel (Custom SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        46\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        62\n",
      "   macro avg       0.37      0.50      0.43        62\n",
      "weighted avg       0.55      0.74      0.63        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marce/Documentos/Ciclo6/Machine Learning/Proyecto1/project-1-classification-2025-1-b/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/marce/Documentos/Ciclo6/Machine Learning/Proyecto1/project-1-classification-2025-1-b/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/marce/Documentos/Ciclo6/Machine Learning/Proyecto1/project-1-classification-2025-1-b/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Separar en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#smote.fit_resample(X_train, y_train)\n",
    "X_train_resampled, y_train_resampled = X_train, y_train\n",
    "\n",
    "svm_gauss = SVM(kernel_type='gauss', regularization_parameter=1.0, gauss_gamma=0.1)\n",
    "svm_gauss.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_gauss_custom = svm_gauss.predict(X_test)\n",
    "accuracy_gauss_custom = accuracy_score(y_test, y_pred_gauss_custom)\n",
    "\n",
    "print(\"gauss Kernel (Custom SVM):\")\n",
    "print(classification_report(y_test, y_pred_gauss_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd9c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf Kernel (Custom SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85        46\n",
      "           1       0.60      0.19      0.29        16\n",
      "\n",
      "    accuracy                           0.76        62\n",
      "   macro avg       0.69      0.57      0.57        62\n",
      "weighted avg       0.73      0.76      0.71        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_sigmoid = SVM(kernel_type='sigmoid', regularization_parameter=1.0, gauss_gamma=0.1)\n",
    "svm_sigmoid.fit(X_train, y_train)\n",
    "y_pred_sigmoid_custom = svm_sigmoid.predict(X_test)\n",
    "\n",
    "print(\"rbf Kernel (Custom SVM):\")\n",
    "print(classification_report(y_test, y_pred_sigmoid_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a88c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf Kernel (Custom SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74        46\n",
      "           1       0.38      0.56      0.45        16\n",
      "\n",
      "    accuracy                           0.65        62\n",
      "   macro avg       0.60      0.62      0.59        62\n",
      "weighted avg       0.70      0.65      0.66        62\n",
      "\n",
      "\\ modelo guardado como 'simple_svm_sigmoid.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_sigmoid = SVM(kernel_type='sigmoid', regularization_parameter=1.0,\n",
    "                  sigmoid_alpha=0.01, sigmoid_c=0)\n",
    "\n",
    "svm_sigmoid.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_sigmoid_custom = svm_sigmoid.predict(X_test)\n",
    "\n",
    "print(\"rbf Kernel (Custom SVM):\")\n",
    "print(classification_report(y_test, y_pred_sigmoid_custom))\n",
    "\n",
    "# Guardar el mejor modelo en un archivo .pkl\n",
    "with open(\"simple_svm_sigmoid.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm_sigmoid, f)\n",
    "\n",
    "print(\"\\ modelo guardado como 'simple_svm_sigmoid.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b343a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.001, c=-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        46\n",
      "           1       0.44      0.50      0.47        16\n",
      "\n",
      "    accuracy                           0.71        62\n",
      "   macro avg       0.63      0.64      0.64        62\n",
      "weighted avg       0.72      0.71      0.71        62\n",
      "\n",
      "alpha=0.001, c=0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80        46\n",
      "           1       0.38      0.31      0.34        16\n",
      "\n",
      "    accuracy                           0.69        62\n",
      "   macro avg       0.58      0.57      0.57        62\n",
      "weighted avg       0.67      0.69      0.68        62\n",
      "\n",
      "alpha=0.001, c=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        46\n",
      "           1       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.71        62\n",
      "   macro avg       0.61      0.60      0.60        62\n",
      "weighted avg       0.70      0.71      0.70        62\n",
      "\n",
      "alpha=0.01, c=-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79        46\n",
      "           1       0.36      0.31      0.33        16\n",
      "\n",
      "    accuracy                           0.68        62\n",
      "   macro avg       0.56      0.56      0.56        62\n",
      "weighted avg       0.66      0.68      0.67        62\n",
      "\n",
      "alpha=0.01, c=0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.73        46\n",
      "           1       0.35      0.50      0.41        16\n",
      "\n",
      "    accuracy                           0.63        62\n",
      "   macro avg       0.57      0.59      0.57        62\n",
      "weighted avg       0.68      0.63      0.65        62\n",
      "\n",
      "alpha=0.01, c=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.26      0.31      0.29        16\n",
      "\n",
      "    accuracy                           0.60        62\n",
      "   macro avg       0.50      0.50      0.50        62\n",
      "weighted avg       0.62      0.60      0.61        62\n",
      "\n",
      "alpha=0.1, c=-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.46      0.56        46\n",
      "           1       0.24      0.50      0.33        16\n",
      "\n",
      "    accuracy                           0.47        62\n",
      "   macro avg       0.48      0.48      0.44        62\n",
      "weighted avg       0.60      0.47      0.50        62\n",
      "\n",
      "alpha=0.1, c=0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.54      0.66        46\n",
      "           1       0.34      0.69      0.46        16\n",
      "\n",
      "    accuracy                           0.58        62\n",
      "   macro avg       0.59      0.62      0.56        62\n",
      "weighted avg       0.71      0.58      0.61        62\n",
      "\n",
      "alpha=0.1, c=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60        46\n",
      "           1       0.31      0.69      0.43        16\n",
      "\n",
      "    accuracy                           0.53        62\n",
      "   macro avg       0.56      0.58      0.52        62\n",
      "weighted avg       0.69      0.53      0.56        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.001, 0.01, 0.1]:\n",
    "    for c in [-1, 0, 1]:\n",
    "        svm_sigmoid = SVM(kernel_type='sigmoid', regularization_parameter=1.0,\n",
    "                          sigmoid_alpha=alpha, sigmoid_c=c)\n",
    "        svm_sigmoid.fit(X_train_resampled, y_train_resampled)\n",
    "        preds = svm_sigmoid.predict(X_test)\n",
    "        print(f\"alpha={alpha}, c={c}\")\n",
    "        print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240b1d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con alpha=0.001, c=-1...\n",
      "F1-macro: 0.6077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        46\n",
      "           1       0.41      0.44      0.42        16\n",
      "\n",
      "    accuracy                           0.69        62\n",
      "   macro avg       0.61      0.61      0.61        62\n",
      "weighted avg       0.70      0.69      0.70        62\n",
      "\n",
      "Entrenando con alpha=0.001, c=0...\n",
      "F1-macro: 0.5724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80        46\n",
      "           1       0.38      0.31      0.34        16\n",
      "\n",
      "    accuracy                           0.69        62\n",
      "   macro avg       0.58      0.57      0.57        62\n",
      "weighted avg       0.67      0.69      0.68        62\n",
      "\n",
      "Entrenando con alpha=0.001, c=1...\n",
      "F1-macro: 0.6043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        46\n",
      "           1       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.71        62\n",
      "   macro avg       0.61      0.60      0.60        62\n",
      "weighted avg       0.70      0.71      0.70        62\n",
      "\n",
      "Entrenando con alpha=0.01, c=-1...\n",
      "F1-macro: 0.5914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        46\n",
      "           1       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.69        62\n",
      "   macro avg       0.59      0.59      0.59        62\n",
      "weighted avg       0.69      0.69      0.69        62\n",
      "\n",
      "Entrenando con alpha=0.01, c=0...\n",
      "F1-macro: 0.5698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.73        46\n",
      "           1       0.35      0.50      0.41        16\n",
      "\n",
      "    accuracy                           0.63        62\n",
      "   macro avg       0.57      0.59      0.57        62\n",
      "weighted avg       0.68      0.63      0.65        62\n",
      "\n",
      "Entrenando con alpha=0.01, c=1...\n",
      "F1-macro: 0.5303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73        46\n",
      "           1       0.30      0.38      0.33        16\n",
      "\n",
      "    accuracy                           0.61        62\n",
      "   macro avg       0.53      0.54      0.53        62\n",
      "weighted avg       0.64      0.61      0.63        62\n",
      "\n",
      "Entrenando con alpha=0.1, c=-1...\n",
      "F1-macro: 0.5068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65        46\n",
      "           1       0.29      0.50      0.36        16\n",
      "\n",
      "    accuracy                           0.55        62\n",
      "   macro avg       0.53      0.53      0.51        62\n",
      "weighted avg       0.64      0.55      0.58        62\n",
      "\n",
      "Entrenando con alpha=0.1, c=0...\n",
      "F1-macro: 0.5445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.52      0.64        46\n",
      "           1       0.33      0.69      0.45        16\n",
      "\n",
      "    accuracy                           0.56        62\n",
      "   macro avg       0.58      0.60      0.54        62\n",
      "weighted avg       0.70      0.56      0.59        62\n",
      "\n",
      "Entrenando con alpha=0.1, c=1...\n",
      "F1-macro: 0.5032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.46      0.58        46\n",
      "           1       0.31      0.69      0.42        16\n",
      "\n",
      "    accuracy                           0.52        62\n",
      "   macro avg       0.56      0.57      0.50        62\n",
      "weighted avg       0.68      0.52      0.54        62\n",
      "\n",
      "\n",
      "Mejor modelo guardado como 'mejor_modelo_svm_sigmoid.pkl'\n",
      "Mejor combinaciÃ³n: alpha=0.001, c=-1, F1-macro=0.6077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for alpha in [0.001, 0.01, 0.1]:\n",
    "    for c in [-1, 0, 1]:\n",
    "        print(f\"Entrenando con alpha={alpha}, c={c}...\")\n",
    "        svm_sigmoid = SVM(kernel_type='sigmoid', regularization_parameter=1.0,\n",
    "                          sigmoid_alpha=alpha, sigmoid_c=c)\n",
    "        svm_sigmoid.fit(X_train_resampled, y_train_resampled)\n",
    "        preds = svm_sigmoid.predict(X_test)\n",
    "\n",
    "        current_f1 = f1_score(y_test, preds, average='macro')\n",
    "        print(f\"F1-macro: {current_f1:.4f}\")\n",
    "        print(classification_report(y_test, preds))\n",
    "\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_model = svm_sigmoid\n",
    "            best_params = (alpha, c)\n",
    "\n",
    "# Guardar el mejor modelo en un archivo .pkl\n",
    "with open(\"mejor_modelo_svm_sigmoid.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"\\nMejor modelo guardado como 'mejor_modelo_svm_sigmoid.pkl'\")\n",
    "print(f\"Mejor combinaciÃ³n: alpha={best_params[0]}, c={best_params[1]}, F1-macro={best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b1187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
